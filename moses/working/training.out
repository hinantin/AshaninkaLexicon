/usr/bin/nohup: ignoring input
perl: warning: Setting locale failed.
perl: warning: Please check that your locale settings:
	LANGUAGE = (unset),
	LC_ALL = (unset),
	LC_PAPER = "es_PE.UTF-8",
	LC_ADDRESS = "es_PE.UTF-8",
	LC_MONETARY = "es_PE.UTF-8",
	LC_NUMERIC = "es_PE.UTF-8",
	LC_TELEPHONE = "es_PE.UTF-8",
	LC_IDENTIFICATION = "es_PE.UTF-8",
	LC_MEASUREMENT = "es_PE.UTF-8",
	LC_TIME = "es_PE.UTF-8",
	LC_NAME = "es_PE.UTF-8",
	LANG = "en_US.UTF-8"
    are supported and installed on your system.
perl: warning: Falling back to a fallback locale ("en_US.UTF-8").
Using SCRIPTS_ROOTDIR: /home/hinantin/ashaninka/mosesdecoder/scripts
Using single-thread GIZA
using gzip 
(1) preparing corpus @ Tue May 26 02:29:06 UTC 2020
Executing: mkdir -p /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus
(1.0) selecting factors @ Tue May 26 02:29:06 UTC 2020
(1.1) running mkcls  @ Tue May 26 02:29:06 UTC 2020
/home/hinantin/ashaninka/mosesdecoder/tools/mkcls -c50 -n2 -p/home/hinantin/ashaninka/AshaninkaMT/moses/sentences.clean.spanish -V/home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/spanish.vcb.classes opt
Executing: /home/hinantin/ashaninka/mosesdecoder/tools/mkcls -c50 -n2 -p/home/hinantin/ashaninka/AshaninkaMT/moses/sentences.clean.spanish -V/home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/spanish.vcb.classes opt

***** 2 runs. (algorithm:TA)*****
;KategProblem:cats: 50   words: 1624

start-costs: MEAN: 68512.8 (68482.2-68543.4)  SIGMA:30.5983   
  end-costs: MEAN: 58213.9 (58122.2-58305.6)  SIGMA:91.7182   
   start-pp: MEAN: 106.447 (106.052-106.842)  SIGMA:0.39499   
     end-pp: MEAN: 30.5312 (30.1916-30.8707)  SIGMA:0.339576   
 iterations: MEAN: 38004.5 (37976-38033)  SIGMA:28.5   
       time: MEAN: 0.43355 (0.433513-0.433587)  SIGMA:3.7e-05   
(1.1) running mkcls  @ Tue May 26 02:29:07 UTC 2020
/home/hinantin/ashaninka/mosesdecoder/tools/mkcls -c50 -n2 -p/home/hinantin/ashaninka/AshaninkaMT/moses/sentences.clean.pan-ashaninka -V/home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/pan-ashaninka.vcb.classes opt
Executing: /home/hinantin/ashaninka/mosesdecoder/tools/mkcls -c50 -n2 -p/home/hinantin/ashaninka/AshaninkaMT/moses/sentences.clean.pan-ashaninka -V/home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/pan-ashaninka.vcb.classes opt

***** 2 runs. (algorithm:TA)*****
;KategProblem:cats: 50   words: 2065

start-costs: MEAN: 39808 (39764.7-39851.3)  SIGMA:43.2616   
  end-costs: MEAN: 32701.5 (32655-32747.9)  SIGMA:46.4339   
   start-pp: MEAN: 184.254 (182.68-185.827)  SIGMA:1.57342   
     end-pp: MEAN: 45.3101 (44.8948-45.7254)  SIGMA:0.415291   
 iterations: MEAN: 47831.5 (47631-48032)  SIGMA:200.5   
       time: MEAN: 0.465341 (0.4644-0.466282)  SIGMA:0.000941   
(1.2) creating vcb file /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/spanish.vcb @ Tue May 26 02:29:08 UTC 2020
(1.2) creating vcb file /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/pan-ashaninka.vcb @ Tue May 26 02:29:08 UTC 2020
(1.3) numberizing corpus /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/spanish-pan-ashaninka-int-train.snt @ Tue May 26 02:29:08 UTC 2020
(1.3) numberizing corpus /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/pan-ashaninka-spanish-int-train.snt @ Tue May 26 02:29:08 UTC 2020
(2) running giza @ Tue May 26 02:29:08 UTC 2020
(2.1a) running snt2cooc spanish-pan-ashaninka @ Tue May 26 02:29:08 UTC 2020

Executing: mkdir -p /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/giza.spanish-pan-ashaninka
Executing: /home/hinantin/ashaninka/mosesdecoder/tools/snt2cooc.out /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/pan-ashaninka.vcb /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/spanish.vcb /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/spanish-pan-ashaninka-int-train.snt > /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/giza.spanish-pan-ashaninka/spanish-pan-ashaninka.cooc
/home/hinantin/ashaninka/mosesdecoder/tools/snt2cooc.out /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/pan-ashaninka.vcb /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/spanish.vcb /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/spanish-pan-ashaninka-int-train.snt > /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/giza.spanish-pan-ashaninka/spanish-pan-ashaninka.cooc
END.
(2.1b) running giza spanish-pan-ashaninka @ Tue May 26 02:29:08 UTC 2020
/home/hinantin/ashaninka/mosesdecoder/tools/GIZA++  -CoocurrenceFile /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/giza.spanish-pan-ashaninka/spanish-pan-ashaninka.cooc -c /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/spanish-pan-ashaninka-int-train.snt -m1 5 -m2 0 -m3 3 -m4 3 -model1dumpfrequency 1 -model4smoothfactor 0.4 -nodumps 1 -nsmooth 4 -o /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/giza.spanish-pan-ashaninka/spanish-pan-ashaninka -onlyaldumps 1 -p0 0.999 -s /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/pan-ashaninka.vcb -t /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/spanish.vcb
Executing: /home/hinantin/ashaninka/mosesdecoder/tools/GIZA++  -CoocurrenceFile /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/giza.spanish-pan-ashaninka/spanish-pan-ashaninka.cooc -c /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/spanish-pan-ashaninka-int-train.snt -m1 5 -m2 0 -m3 3 -m4 3 -model1dumpfrequency 1 -model4smoothfactor 0.4 -nodumps 1 -nsmooth 4 -o /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/giza.spanish-pan-ashaninka/spanish-pan-ashaninka -onlyaldumps 1 -p0 0.999 -s /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/pan-ashaninka.vcb -t /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/spanish.vcb
/home/hinantin/ashaninka/mosesdecoder/tools/GIZA++  -CoocurrenceFile /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/giza.spanish-pan-ashaninka/spanish-pan-ashaninka.cooc -c /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/spanish-pan-ashaninka-int-train.snt -m1 5 -m2 0 -m3 3 -m4 3 -model1dumpfrequency 1 -model4smoothfactor 0.4 -nodumps 1 -nsmooth 4 -o /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/giza.spanish-pan-ashaninka/spanish-pan-ashaninka -onlyaldumps 1 -p0 0.999 -s /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/pan-ashaninka.vcb -t /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/spanish.vcb
Parameter 'coocurrencefile' changed from '' to '/home/hinantin/ashaninka/AshaninkaMT/moses/working/train/giza.spanish-pan-ashaninka/spanish-pan-ashaninka.cooc'
Parameter 'c' changed from '' to '/home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/spanish-pan-ashaninka-int-train.snt'
Parameter 'm3' changed from '5' to '3'
Parameter 'm4' changed from '5' to '3'
Parameter 'model1dumpfrequency' changed from '0' to '1'
Parameter 'model4smoothfactor' changed from '0.2' to '0.4'
Parameter 'nodumps' changed from '0' to '1'
Parameter 'nsmooth' changed from '64' to '4'
Parameter 'o' changed from '2020-05-26.022908.root' to '/home/hinantin/ashaninka/AshaninkaMT/moses/working/train/giza.spanish-pan-ashaninka/spanish-pan-ashaninka'
Parameter 'onlyaldumps' changed from '0' to '1'
Parameter 'p0' changed from '-1' to '0.999'
Parameter 's' changed from '' to '/home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/pan-ashaninka.vcb'
Parameter 't' changed from '' to '/home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/spanish.vcb'
general parameters:
-------------------
ml = 101  (maximum sentence length)

No. of iterations:
-------------------
hmmiterations = 5  (mh)
model1iterations = 5  (number of iterations for Model 1)
model2iterations = 0  (number of iterations for Model 2)
model3iterations = 3  (number of iterations for Model 3)
model4iterations = 3  (number of iterations for Model 4)
model5iterations = 0  (number of iterations for Model 5)
model6iterations = 0  (number of iterations for Model 6)

parameter for various heuristics in GIZA++ for efficient training:
------------------------------------------------------------------
countincreasecutoff = 1e-06  (Counts increment cutoff threshold)
countincreasecutoffal = 1e-05  (Counts increment cutoff threshold for alignments in training of fertility models)
mincountincrease = 1e-07  (minimal count increase)
peggedcutoff = 0.03  (relative cutoff probability for alignment-centers in pegging)
probcutoff = 1e-07  (Probability cutoff threshold for lexicon probabilities)
probsmooth = 1e-07  (probability smoothing (floor) value )

parameters for describing the type and amount of output:
-----------------------------------------------------------
compactalignmentformat = 0  (0: detailled alignment format, 1: compact alignment format )
hmmdumpfrequency = 0  (dump frequency of HMM)
l = 2020-05-26.022908.root.log  (log file name)
log = 0  (0: no logfile; 1: logfile)
model1dumpfrequency = 1  (dump frequency of Model 1)
model2dumpfrequency = 0  (dump frequency of Model 2)
model345dumpfrequency = 0  (dump frequency of Model 3/4/5)
nbestalignments = 0  (for printing the n best alignments)
nodumps = 1  (1: do not write any files)
o = /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/giza.spanish-pan-ashaninka/spanish-pan-ashaninka  (output file prefix)
onlyaldumps = 1  (1: do not write any files)
outputpath =   (output path)
transferdumpfrequency = 0  (output: dump of transfer from Model 2 to 3)
verbose = 0  (0: not verbose; 1: verbose)
verbosesentence = -10  (number of sentence for which a lot of information should be printed (negative: no output))

parameters describing input files:
----------------------------------
c = /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/spanish-pan-ashaninka-int-train.snt  (training corpus file name)
d =   (dictionary file name)
s = /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/pan-ashaninka.vcb  (source vocabulary file name)
t = /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/spanish.vcb  (target vocabulary file name)
tc =   (test corpus file name)

smoothing parameters:
---------------------
emalsmooth = 0.2  (f-b-trn: smoothing factor for HMM alignment model (can be ignored by -emSmoothHMM))
model23smoothfactor = 0  (smoothing parameter for IBM-2/3 (interpolation with constant))
model4smoothfactor = 0.4  (smooting parameter for alignment probabilities in Model 4)
model5smoothfactor = 0.1  (smooting parameter for distortion probabilities in Model 5 (linear interpolation with constant))
nsmooth = 4  (smoothing for fertility parameters (good value: 64): weight for wordlength-dependent fertility parameters)
nsmoothgeneral = 0  (smoothing for fertility parameters (default: 0): weight for word-independent fertility parameters)

parameters modifying the models:
--------------------------------
compactadtable = 1  (1: only 3-dimensional alignment table for IBM-2 and IBM-3)
deficientdistortionforemptyword = 0  (0: IBM-3/IBM-4 as described in (Brown et al. 1993); 1: distortion model of empty word is deficient; 2: distoriton model of empty word is deficient (differently); setting this parameter also helps to avoid that during IBM-3 and IBM-4 training too many words are aligned with the empty word)
depm4 = 76  (d_{=1}: &1:l, &2:m, &4:F, &8:E, d_{>1}&16:l, &32:m, &64:F, &128:E)
depm5 = 68  (d_{=1}: &1:l, &2:m, &4:F, &8:E, d_{>1}&16:l, &32:m, &64:F, &128:E)
emalignmentdependencies = 2  (lextrain: dependencies in the HMM alignment model.  &1: sentence length; &2: previous class; &4: previous position;  &8: French position; &16: French class)
emprobforempty = 0.4  (f-b-trn: probability for empty word)

parameters modifying the EM-algorithm:
--------------------------------------
m5p0 = -1  (fixed value for parameter p_0 in IBM-5 (if negative then it is determined in training))
manlexfactor1 = 0  ()
manlexfactor2 = 0  ()
manlexmaxmultiplicity = 20  ()
maxfertility = 10  (maximal fertility for fertility models)
p0 = 0.999  (fixed value for parameter p_0 in IBM-3/4 (if negative then it is determined in training))
pegging = 0  (0: no pegging; 1: do pegging)

general parameters:
-------------------
ml = 101  (maximum sentence length)

No. of iterations:
-------------------
hmmiterations = 5  (mh)
model1iterations = 5  (number of iterations for Model 1)
model2iterations = 0  (number of iterations for Model 2)
model3iterations = 3  (number of iterations for Model 3)
model4iterations = 3  (number of iterations for Model 4)
model5iterations = 0  (number of iterations for Model 5)
model6iterations = 0  (number of iterations for Model 6)

parameter for various heuristics in GIZA++ for efficient training:
------------------------------------------------------------------
countincreasecutoff = 1e-06  (Counts increment cutoff threshold)
countincreasecutoffal = 1e-05  (Counts increment cutoff threshold for alignments in training of fertility models)
mincountincrease = 1e-07  (minimal count increase)
peggedcutoff = 0.03  (relative cutoff probability for alignment-centers in pegging)
probcutoff = 1e-07  (Probability cutoff threshold for lexicon probabilities)
probsmooth = 1e-07  (probability smoothing (floor) value )

parameters for describing the type and amount of output:
-----------------------------------------------------------
compactalignmentformat = 0  (0: detailled alignment format, 1: compact alignment format )
hmmdumpfrequency = 0  (dump frequency of HMM)
l = 2020-05-26.022908.root.log  (log file name)
log = 0  (0: no logfile; 1: logfile)
model1dumpfrequency = 1  (dump frequency of Model 1)
model2dumpfrequency = 0  (dump frequency of Model 2)
model345dumpfrequency = 0  (dump frequency of Model 3/4/5)
nbestalignments = 0  (for printing the n best alignments)
nodumps = 1  (1: do not write any files)
o = /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/giza.spanish-pan-ashaninka/spanish-pan-ashaninka  (output file prefix)
onlyaldumps = 1  (1: do not write any files)
outputpath =   (output path)
transferdumpfrequency = 0  (output: dump of transfer from Model 2 to 3)
verbose = 0  (0: not verbose; 1: verbose)
verbosesentence = -10  (number of sentence for which a lot of information should be printed (negative: no output))

parameters describing input files:
----------------------------------
c = /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/spanish-pan-ashaninka-int-train.snt  (training corpus file name)
d =   (dictionary file name)
s = /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/pan-ashaninka.vcb  (source vocabulary file name)
t = /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/spanish.vcb  (target vocabulary file name)
tc =   (test corpus file name)

smoothing parameters:
---------------------
emalsmooth = 0.2  (f-b-trn: smoothing factor for HMM alignment model (can be ignored by -emSmoothHMM))
model23smoothfactor = 0  (smoothing parameter for IBM-2/3 (interpolation with constant))
model4smoothfactor = 0.4  (smooting parameter for alignment probabilities in Model 4)
model5smoothfactor = 0.1  (smooting parameter for distortion probabilities in Model 5 (linear interpolation with constant))
nsmooth = 4  (smoothing for fertility parameters (good value: 64): weight for wordlength-dependent fertility parameters)
nsmoothgeneral = 0  (smoothing for fertility parameters (default: 0): weight for word-independent fertility parameters)

parameters modifying the models:
--------------------------------
compactadtable = 1  (1: only 3-dimensional alignment table for IBM-2 and IBM-3)
deficientdistortionforemptyword = 0  (0: IBM-3/IBM-4 as described in (Brown et al. 1993); 1: distortion model of empty word is deficient; 2: distoriton model of empty word is deficient (differently); setting this parameter also helps to avoid that during IBM-3 and IBM-4 training too many words are aligned with the empty word)
depm4 = 76  (d_{=1}: &1:l, &2:m, &4:F, &8:E, d_{>1}&16:l, &32:m, &64:F, &128:E)
depm5 = 68  (d_{=1}: &1:l, &2:m, &4:F, &8:E, d_{>1}&16:l, &32:m, &64:F, &128:E)
emalignmentdependencies = 2  (lextrain: dependencies in the HMM alignment model.  &1: sentence length; &2: previous class; &4: previous position;  &8: French position; &16: French class)
emprobforempty = 0.4  (f-b-trn: probability for empty word)

parameters modifying the EM-algorithm:
--------------------------------------
m5p0 = -1  (fixed value for parameter p_0 in IBM-5 (if negative then it is determined in training))
manlexfactor1 = 0  ()
manlexfactor2 = 0  ()
manlexmaxmultiplicity = 20  ()
maxfertility = 10  (maximal fertility for fertility models)
p0 = 0.999  (fixed value for parameter p_0 in IBM-3/4 (if negative then it is determined in training))
pegging = 0  (0: no pegging; 1: do pegging)

reading vocabulary files 
Reading vocabulary file from:/home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/pan-ashaninka.vcb
Reading vocabulary file from:/home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/spanish.vcb
Source vocabulary list has 2066 unique tokens 
Target vocabulary list has 1625 unique tokens 
Calculating vocabulary frequencies from corpus /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/spanish-pan-ashaninka-int-train.snt
Reading more sentence pairs into memory ... 
Corpus fits in memory, corpus has: 746 sentence pairs.
 Train total # sentence pairs (weighted): 746
Size of source portion of the training corpus: 4320 tokens
Size of the target portion of the training corpus: 7500 tokens 
In source portion of the training corpus, only 2065 unique tokens appeared
In target portion of the training corpus, only 1623 unique tokens appeared
lambda for PP calculation in IBM-1,IBM-2,HMM:= 7500/(5066-746)== 1.73611
There are 33013 33013 entries in table
==========================================================
Model1 Training Started at: Tue May 26 02:29:08 2020

-----------
Model1: Iteration 1
Model1: (1) TRAIN CROSS-ENTROPY 11.1224 PERPLEXITY 2229.36
Model1: (1) VITERBI TRAIN CROSS-ENTROPY 13.9146 PERPLEXITY 15442.1
Model 1 Iteration: 1 took: 0 seconds
-----------
Model1: Iteration 2
Model1: (2) TRAIN CROSS-ENTROPY 4.67373 PERPLEXITY 25.523
Model1: (2) VITERBI TRAIN CROSS-ENTROPY 6.52309 PERPLEXITY 91.97
Model 1 Iteration: 2 took: 0 seconds
-----------
Model1: Iteration 3
Model1: (3) TRAIN CROSS-ENTROPY 4.37672 PERPLEXITY 20.7742
Model1: (3) VITERBI TRAIN CROSS-ENTROPY 5.96078 PERPLEXITY 62.2834
Model 1 Iteration: 3 took: 0 seconds
-----------
Model1: Iteration 4
Model1: (4) TRAIN CROSS-ENTROPY 4.24737 PERPLEXITY 18.9927
Model1: (4) VITERBI TRAIN CROSS-ENTROPY 5.63255 PERPLEXITY 49.6096
Model 1 Iteration: 4 took: 0 seconds
-----------
Model1: Iteration 5
Model1: (5) TRAIN CROSS-ENTROPY 4.18486 PERPLEXITY 18.1873
Model1: (5) VITERBI TRAIN CROSS-ENTROPY 5.4451 PERPLEXITY 43.5651
Model 1 Iteration: 5 took: 0 seconds
Entire Model1 Training took: 0 seconds
NOTE: I am doing iterations with the HMM model!
Read classes: #words: 2065  #classes: 51
Read classes: #words: 1624  #classes: 51

==========================================================
Hmm Training Started at: Tue May 26 02:29:08 2020

-----------
Hmm: Iteration 1
A/D table contains 1556 parameters.
Hmm: (1) TRAIN CROSS-ENTROPY 4.15008 PERPLEXITY 17.754
Hmm: (1) VITERBI TRAIN CROSS-ENTROPY 5.32889 PERPLEXITY 40.1934

Hmm Iteration: 1 took: 0 seconds

-----------
Hmm: Iteration 2
A/D table contains 1556 parameters.
Hmm: (2) TRAIN CROSS-ENTROPY 4.02541 PERPLEXITY 16.2843
Hmm: (2) VITERBI TRAIN CROSS-ENTROPY 4.84169 PERPLEXITY 28.6744

Hmm Iteration: 2 took: 0 seconds

-----------
Hmm: Iteration 3
A/D table contains 1556 parameters.
Hmm: (3) TRAIN CROSS-ENTROPY 3.79426 PERPLEXITY 13.8735
Hmm: (3) VITERBI TRAIN CROSS-ENTROPY 4.40072 PERPLEXITY 21.1226

Hmm Iteration: 3 took: 0 seconds

-----------
Hmm: Iteration 4
A/D table contains 1556 parameters.
Hmm: (4) TRAIN CROSS-ENTROPY 3.55071 PERPLEXITY 11.7184
Hmm: (4) VITERBI TRAIN CROSS-ENTROPY 3.99939 PERPLEXITY 15.9932

Hmm Iteration: 4 took: 0 seconds

-----------
Hmm: Iteration 5
A/D table contains 1556 parameters.
Hmm: (5) TRAIN CROSS-ENTROPY 3.34465 PERPLEXITY 10.1587
Hmm: (5) VITERBI TRAIN CROSS-ENTROPY 3.69034 PERPLEXITY 12.9093

Hmm Iteration: 5 took: 0 seconds

Entire Hmm Training took: 0 seconds
==========================================================
Read classes: #words: 2065  #classes: 51
Read classes: #words: 1624  #classes: 51
Read classes: #words: 2065  #classes: 51
Read classes: #words: 1624  #classes: 51

==========================================================
Starting H333444:  Viterbi Training
 H333444 Training Started at: Tue May 26 02:29:08 2020


---------------------
THTo3: Iteration 1
#centers(pre/hillclimbed/real): 1 1 1  #al: 105.105 #alsophisticatedcountcollection: 0 #hcsteps: 0
#peggingImprovements: 0
A/D table contains 1556 parameters.
A/D table contains 2551 parameters.
NTable contains 20660 parameter.
p0_count is 6441.55 and p1 is 529.225; p0 is 0.999 p1: 0.001
THTo3: TRAIN CROSS-ENTROPY 2.86425 PERPLEXITY 7.28158
THTo3: (1) TRAIN VITERBI CROSS-ENTROPY 3.0358 PERPLEXITY 8.20101

THTo3 Viterbi Iteration : 1 took: 0 seconds

---------------------
Model3: Iteration 2
#centers(pre/hillclimbed/real): 1 1 1  #al: 104.835 #alsophisticatedcountcollection: 0 #hcsteps: 1.85121
#peggingImprovements: 0
A/D table contains 1556 parameters.
A/D table contains 2547 parameters.
NTable contains 20660 parameter.
p0_count is 7215.99 and p1 is 142.005; p0 is 0.999 p1: 0.001
Model3: TRAIN CROSS-ENTROPY 3.81322 PERPLEXITY 14.0571
Model3: (2) TRAIN VITERBI CROSS-ENTROPY 3.91431 PERPLEXITY 15.0774

Model3 Viterbi Iteration : 2 took: 0 seconds

---------------------
Model3: Iteration 3
#centers(pre/hillclimbed/real): 1 1 1  #al: 104.866 #alsophisticatedcountcollection: 0 #hcsteps: 1.72252
#peggingImprovements: 0
A/D table contains 1556 parameters.
A/D table contains 2547 parameters.
NTable contains 20660 parameter.
p0_count is 7359.49 and p1 is 70.2547; p0 is 0.999 p1: 0.001
Model3: TRAIN CROSS-ENTROPY 3.58367 PERPLEXITY 11.9893
Model3: (3) TRAIN VITERBI CROSS-ENTROPY 3.6542 PERPLEXITY 12.59

Model3 Viterbi Iteration : 3 took: 0 seconds

---------------------
T3To4: Iteration 4
#centers(pre/hillclimbed/real): 1 1 1  #al: 104.916 #alsophisticatedcountcollection: 11.5576 #hcsteps: 1.68901
#peggingImprovements: 0
D4 table contains 401331 parameters.
A/D table contains 1556 parameters.
A/D table contains 2547 parameters.
NTable contains 20660 parameter.
p0_count is 7406.5 and p1 is 46.7512; p0 is 0.999 p1: 0.001
T3To4: TRAIN CROSS-ENTROPY 3.49109 PERPLEXITY 11.244
T3To4: (4) TRAIN VITERBI CROSS-ENTROPY 3.54357 PERPLEXITY 11.6606

T3To4 Viterbi Iteration : 4 took: 0 seconds

---------------------
Model4: Iteration 5
#centers(pre/hillclimbed/real): 1 1 1  #al: 104.897 #alsophisticatedcountcollection: 7.44906 #hcsteps: 1.6059
#peggingImprovements: 0
D4 table contains 401331 parameters.
A/D table contains 1556 parameters.
A/D table contains 2547 parameters.
NTable contains 20660 parameter.
p0_count is 7418.87 and p1 is 40.5656; p0 is 0.999 p1: 0.001
Model4: TRAIN CROSS-ENTROPY 3.20397 PERPLEXITY 9.21493
Model4: (5) TRAIN VITERBI CROSS-ENTROPY 3.23436 PERPLEXITY 9.41109

Model4 Viterbi Iteration : 5 took: 0 seconds

---------------------
Model4: Iteration 6
#centers(pre/hillclimbed/real): 1 1 1  #al: 104.905 #alsophisticatedcountcollection: 5.46381 #hcsteps: 1.55496
#peggingImprovements: 0
D4 table contains 401331 parameters.
A/D table contains 1556 parameters.
A/D table contains 2523 parameters.
NTable contains 20660 parameter.
p0_count is 7424.99 and p1 is 37.5058; p0 is 0.999 p1: 0.001
Model4: TRAIN CROSS-ENTROPY 3.10205 PERPLEXITY 8.5864
Model4: (6) TRAIN VITERBI CROSS-ENTROPY 3.12281 PERPLEXITY 8.71085

Model4 Viterbi Iteration : 6 took: 0 seconds
H333444 Training Finished at: Tue May 26 02:29:08 2020


Entire Viterbi H333444 Training took: 0 seconds
==========================================================

Entire Training took: 0 seconds
Program Finished at: Tue May 26 02:29:08 2020

==========================================================
Executing: rm -f /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/giza.spanish-pan-ashaninka/spanish-pan-ashaninka.A3.final.gz
Executing: gzip /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/giza.spanish-pan-ashaninka/spanish-pan-ashaninka.A3.final
(2.1a) running snt2cooc pan-ashaninka-spanish @ Tue May 26 02:29:08 UTC 2020

Executing: mkdir -p /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/giza.pan-ashaninka-spanish
Executing: /home/hinantin/ashaninka/mosesdecoder/tools/snt2cooc.out /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/spanish.vcb /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/pan-ashaninka.vcb /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/pan-ashaninka-spanish-int-train.snt > /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/giza.pan-ashaninka-spanish/pan-ashaninka-spanish.cooc
/home/hinantin/ashaninka/mosesdecoder/tools/snt2cooc.out /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/spanish.vcb /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/pan-ashaninka.vcb /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/pan-ashaninka-spanish-int-train.snt > /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/giza.pan-ashaninka-spanish/pan-ashaninka-spanish.cooc
END.
(2.1b) running giza pan-ashaninka-spanish @ Tue May 26 02:29:08 UTC 2020
/home/hinantin/ashaninka/mosesdecoder/tools/GIZA++  -CoocurrenceFile /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/giza.pan-ashaninka-spanish/pan-ashaninka-spanish.cooc -c /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/pan-ashaninka-spanish-int-train.snt -m1 5 -m2 0 -m3 3 -m4 3 -model1dumpfrequency 1 -model4smoothfactor 0.4 -nodumps 1 -nsmooth 4 -o /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/giza.pan-ashaninka-spanish/pan-ashaninka-spanish -onlyaldumps 1 -p0 0.999 -s /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/spanish.vcb -t /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/pan-ashaninka.vcb
Executing: /home/hinantin/ashaninka/mosesdecoder/tools/GIZA++  -CoocurrenceFile /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/giza.pan-ashaninka-spanish/pan-ashaninka-spanish.cooc -c /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/pan-ashaninka-spanish-int-train.snt -m1 5 -m2 0 -m3 3 -m4 3 -model1dumpfrequency 1 -model4smoothfactor 0.4 -nodumps 1 -nsmooth 4 -o /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/giza.pan-ashaninka-spanish/pan-ashaninka-spanish -onlyaldumps 1 -p0 0.999 -s /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/spanish.vcb -t /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/pan-ashaninka.vcb
/home/hinantin/ashaninka/mosesdecoder/tools/GIZA++  -CoocurrenceFile /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/giza.pan-ashaninka-spanish/pan-ashaninka-spanish.cooc -c /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/pan-ashaninka-spanish-int-train.snt -m1 5 -m2 0 -m3 3 -m4 3 -model1dumpfrequency 1 -model4smoothfactor 0.4 -nodumps 1 -nsmooth 4 -o /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/giza.pan-ashaninka-spanish/pan-ashaninka-spanish -onlyaldumps 1 -p0 0.999 -s /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/spanish.vcb -t /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/pan-ashaninka.vcb
Parameter 'coocurrencefile' changed from '' to '/home/hinantin/ashaninka/AshaninkaMT/moses/working/train/giza.pan-ashaninka-spanish/pan-ashaninka-spanish.cooc'
Parameter 'c' changed from '' to '/home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/pan-ashaninka-spanish-int-train.snt'
Parameter 'm3' changed from '5' to '3'
Parameter 'm4' changed from '5' to '3'
Parameter 'model1dumpfrequency' changed from '0' to '1'
Parameter 'model4smoothfactor' changed from '0.2' to '0.4'
Parameter 'nodumps' changed from '0' to '1'
Parameter 'nsmooth' changed from '64' to '4'
Parameter 'o' changed from '2020-05-26.022908.root' to '/home/hinantin/ashaninka/AshaninkaMT/moses/working/train/giza.pan-ashaninka-spanish/pan-ashaninka-spanish'
Parameter 'onlyaldumps' changed from '0' to '1'
Parameter 'p0' changed from '-1' to '0.999'
Parameter 's' changed from '' to '/home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/spanish.vcb'
Parameter 't' changed from '' to '/home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/pan-ashaninka.vcb'
general parameters:
-------------------
ml = 101  (maximum sentence length)

No. of iterations:
-------------------
hmmiterations = 5  (mh)
model1iterations = 5  (number of iterations for Model 1)
model2iterations = 0  (number of iterations for Model 2)
model3iterations = 3  (number of iterations for Model 3)
model4iterations = 3  (number of iterations for Model 4)
model5iterations = 0  (number of iterations for Model 5)
model6iterations = 0  (number of iterations for Model 6)

parameter for various heuristics in GIZA++ for efficient training:
------------------------------------------------------------------
countincreasecutoff = 1e-06  (Counts increment cutoff threshold)
countincreasecutoffal = 1e-05  (Counts increment cutoff threshold for alignments in training of fertility models)
mincountincrease = 1e-07  (minimal count increase)
peggedcutoff = 0.03  (relative cutoff probability for alignment-centers in pegging)
probcutoff = 1e-07  (Probability cutoff threshold for lexicon probabilities)
probsmooth = 1e-07  (probability smoothing (floor) value )

parameters for describing the type and amount of output:
-----------------------------------------------------------
compactalignmentformat = 0  (0: detailled alignment format, 1: compact alignment format )
hmmdumpfrequency = 0  (dump frequency of HMM)
l = 2020-05-26.022908.root.log  (log file name)
log = 0  (0: no logfile; 1: logfile)
model1dumpfrequency = 1  (dump frequency of Model 1)
model2dumpfrequency = 0  (dump frequency of Model 2)
model345dumpfrequency = 0  (dump frequency of Model 3/4/5)
nbestalignments = 0  (for printing the n best alignments)
nodumps = 1  (1: do not write any files)
o = /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/giza.pan-ashaninka-spanish/pan-ashaninka-spanish  (output file prefix)
onlyaldumps = 1  (1: do not write any files)
outputpath =   (output path)
transferdumpfrequency = 0  (output: dump of transfer from Model 2 to 3)
verbose = 0  (0: not verbose; 1: verbose)
verbosesentence = -10  (number of sentence for which a lot of information should be printed (negative: no output))

parameters describing input files:
----------------------------------
c = /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/pan-ashaninka-spanish-int-train.snt  (training corpus file name)
d =   (dictionary file name)
s = /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/spanish.vcb  (source vocabulary file name)
t = /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/pan-ashaninka.vcb  (target vocabulary file name)
tc =   (test corpus file name)

smoothing parameters:
---------------------
emalsmooth = 0.2  (f-b-trn: smoothing factor for HMM alignment model (can be ignored by -emSmoothHMM))
model23smoothfactor = 0  (smoothing parameter for IBM-2/3 (interpolation with constant))
model4smoothfactor = 0.4  (smooting parameter for alignment probabilities in Model 4)
model5smoothfactor = 0.1  (smooting parameter for distortion probabilities in Model 5 (linear interpolation with constant))
nsmooth = 4  (smoothing for fertility parameters (good value: 64): weight for wordlength-dependent fertility parameters)
nsmoothgeneral = 0  (smoothing for fertility parameters (default: 0): weight for word-independent fertility parameters)

parameters modifying the models:
--------------------------------
compactadtable = 1  (1: only 3-dimensional alignment table for IBM-2 and IBM-3)
deficientdistortionforemptyword = 0  (0: IBM-3/IBM-4 as described in (Brown et al. 1993); 1: distortion model of empty word is deficient; 2: distoriton model of empty word is deficient (differently); setting this parameter also helps to avoid that during IBM-3 and IBM-4 training too many words are aligned with the empty word)
depm4 = 76  (d_{=1}: &1:l, &2:m, &4:F, &8:E, d_{>1}&16:l, &32:m, &64:F, &128:E)
depm5 = 68  (d_{=1}: &1:l, &2:m, &4:F, &8:E, d_{>1}&16:l, &32:m, &64:F, &128:E)
emalignmentdependencies = 2  (lextrain: dependencies in the HMM alignment model.  &1: sentence length; &2: previous class; &4: previous position;  &8: French position; &16: French class)
emprobforempty = 0.4  (f-b-trn: probability for empty word)

parameters modifying the EM-algorithm:
--------------------------------------
m5p0 = -1  (fixed value for parameter p_0 in IBM-5 (if negative then it is determined in training))
manlexfactor1 = 0  ()
manlexfactor2 = 0  ()
manlexmaxmultiplicity = 20  ()
maxfertility = 10  (maximal fertility for fertility models)
p0 = 0.999  (fixed value for parameter p_0 in IBM-3/4 (if negative then it is determined in training))
pegging = 0  (0: no pegging; 1: do pegging)

general parameters:
-------------------
ml = 101  (maximum sentence length)

No. of iterations:
-------------------
hmmiterations = 5  (mh)
model1iterations = 5  (number of iterations for Model 1)
model2iterations = 0  (number of iterations for Model 2)
model3iterations = 3  (number of iterations for Model 3)
model4iterations = 3  (number of iterations for Model 4)
model5iterations = 0  (number of iterations for Model 5)
model6iterations = 0  (number of iterations for Model 6)

parameter for various heuristics in GIZA++ for efficient training:
------------------------------------------------------------------
countincreasecutoff = 1e-06  (Counts increment cutoff threshold)
countincreasecutoffal = 1e-05  (Counts increment cutoff threshold for alignments in training of fertility models)
mincountincrease = 1e-07  (minimal count increase)
peggedcutoff = 0.03  (relative cutoff probability for alignment-centers in pegging)
probcutoff = 1e-07  (Probability cutoff threshold for lexicon probabilities)
probsmooth = 1e-07  (probability smoothing (floor) value )

parameters for describing the type and amount of output:
-----------------------------------------------------------
compactalignmentformat = 0  (0: detailled alignment format, 1: compact alignment format )
hmmdumpfrequency = 0  (dump frequency of HMM)
l = 2020-05-26.022908.root.log  (log file name)
log = 0  (0: no logfile; 1: logfile)
model1dumpfrequency = 1  (dump frequency of Model 1)
model2dumpfrequency = 0  (dump frequency of Model 2)
model345dumpfrequency = 0  (dump frequency of Model 3/4/5)
nbestalignments = 0  (for printing the n best alignments)
nodumps = 1  (1: do not write any files)
o = /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/giza.pan-ashaninka-spanish/pan-ashaninka-spanish  (output file prefix)
onlyaldumps = 1  (1: do not write any files)
outputpath =   (output path)
transferdumpfrequency = 0  (output: dump of transfer from Model 2 to 3)
verbose = 0  (0: not verbose; 1: verbose)
verbosesentence = -10  (number of sentence for which a lot of information should be printed (negative: no output))

parameters describing input files:
----------------------------------
c = /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/pan-ashaninka-spanish-int-train.snt  (training corpus file name)
d =   (dictionary file name)
s = /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/spanish.vcb  (source vocabulary file name)
t = /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/pan-ashaninka.vcb  (target vocabulary file name)
tc =   (test corpus file name)

smoothing parameters:
---------------------
emalsmooth = 0.2  (f-b-trn: smoothing factor for HMM alignment model (can be ignored by -emSmoothHMM))
model23smoothfactor = 0  (smoothing parameter for IBM-2/3 (interpolation with constant))
model4smoothfactor = 0.4  (smooting parameter for alignment probabilities in Model 4)
model5smoothfactor = 0.1  (smooting parameter for distortion probabilities in Model 5 (linear interpolation with constant))
nsmooth = 4  (smoothing for fertility parameters (good value: 64): weight for wordlength-dependent fertility parameters)
nsmoothgeneral = 0  (smoothing for fertility parameters (default: 0): weight for word-independent fertility parameters)

parameters modifying the models:
--------------------------------
compactadtable = 1  (1: only 3-dimensional alignment table for IBM-2 and IBM-3)
deficientdistortionforemptyword = 0  (0: IBM-3/IBM-4 as described in (Brown et al. 1993); 1: distortion model of empty word is deficient; 2: distoriton model of empty word is deficient (differently); setting this parameter also helps to avoid that during IBM-3 and IBM-4 training too many words are aligned with the empty word)
depm4 = 76  (d_{=1}: &1:l, &2:m, &4:F, &8:E, d_{>1}&16:l, &32:m, &64:F, &128:E)
depm5 = 68  (d_{=1}: &1:l, &2:m, &4:F, &8:E, d_{>1}&16:l, &32:m, &64:F, &128:E)
emalignmentdependencies = 2  (lextrain: dependencies in the HMM alignment model.  &1: sentence length; &2: previous class; &4: previous position;  &8: French position; &16: French class)
emprobforempty = 0.4  (f-b-trn: probability for empty word)

parameters modifying the EM-algorithm:
--------------------------------------
m5p0 = -1  (fixed value for parameter p_0 in IBM-5 (if negative then it is determined in training))
manlexfactor1 = 0  ()
manlexfactor2 = 0  ()
manlexmaxmultiplicity = 20  ()
maxfertility = 10  (maximal fertility for fertility models)
p0 = 0.999  (fixed value for parameter p_0 in IBM-3/4 (if negative then it is determined in training))
pegging = 0  (0: no pegging; 1: do pegging)

reading vocabulary files 
Reading vocabulary file from:/home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/spanish.vcb
Reading vocabulary file from:/home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/pan-ashaninka.vcb
Source vocabulary list has 1625 unique tokens 
Target vocabulary list has 2066 unique tokens 
Calculating vocabulary frequencies from corpus /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/corpus/pan-ashaninka-spanish-int-train.snt
Reading more sentence pairs into memory ... 
Corpus fits in memory, corpus has: 746 sentence pairs.
 Train total # sentence pairs (weighted): 746
Size of source portion of the training corpus: 7500 tokens
Size of the target portion of the training corpus: 4320 tokens 
In source portion of the training corpus, only 1624 unique tokens appeared
In target portion of the training corpus, only 2064 unique tokens appeared
lambda for PP calculation in IBM-1,IBM-2,HMM:= 4320/(8246-746)== 0.576
There are 33454 33454 entries in table
==========================================================
Model1 Training Started at: Tue May 26 02:29:08 2020

-----------
Model1: Iteration 1
Model1: (1) TRAIN CROSS-ENTROPY 11.8537 PERPLEXITY 3701.11
Model1: (1) VITERBI TRAIN CROSS-ENTROPY 15.3359 PERPLEXITY 41359.9
Model 1 Iteration: 1 took: 0 seconds
-----------
Model1: Iteration 2
Model1: (2) TRAIN CROSS-ENTROPY 5.27165 PERPLEXITY 38.6301
Model1: (2) VITERBI TRAIN CROSS-ENTROPY 7.02247 PERPLEXITY 130.009
Model 1 Iteration: 2 took: 0 seconds
-----------
Model1: Iteration 3
Model1: (3) TRAIN CROSS-ENTROPY 4.75439 PERPLEXITY 26.9907
Model1: (3) VITERBI TRAIN CROSS-ENTROPY 6.16189 PERPLEXITY 71.6
Model 1 Iteration: 3 took: 0 seconds
-----------
Model1: Iteration 4
Model1: (4) TRAIN CROSS-ENTROPY 4.55252 PERPLEXITY 23.4664
Model1: (4) VITERBI TRAIN CROSS-ENTROPY 5.80268 PERPLEXITY 55.8187
Model 1 Iteration: 4 took: 0 seconds
-----------
Model1: Iteration 5
Model1: (5) TRAIN CROSS-ENTROPY 4.47376 PERPLEXITY 22.2196
Model1: (5) VITERBI TRAIN CROSS-ENTROPY 5.63605 PERPLEXITY 49.7302
Model 1 Iteration: 5 took: 0 seconds
Entire Model1 Training took: 0 seconds
NOTE: I am doing iterations with the HMM model!
Read classes: #words: 1624  #classes: 51
Read classes: #words: 2065  #classes: 51

==========================================================
Hmm Training Started at: Tue May 26 02:29:08 2020

-----------
Hmm: Iteration 1
A/D table contains 2469 parameters.
Hmm: (1) TRAIN CROSS-ENTROPY 4.43753 PERPLEXITY 21.6685
Hmm: (1) VITERBI TRAIN CROSS-ENTROPY 5.54511 PERPLEXITY 46.6921

Hmm Iteration: 1 took: 0 seconds

-----------
Hmm: Iteration 2
A/D table contains 2469 parameters.
Hmm: (2) TRAIN CROSS-ENTROPY 4.19518 PERPLEXITY 18.3179
Hmm: (2) VITERBI TRAIN CROSS-ENTROPY 4.8829 PERPLEXITY 29.5053

Hmm Iteration: 2 took: 0 seconds

-----------
Hmm: Iteration 3
A/D table contains 2469 parameters.
Hmm: (3) TRAIN CROSS-ENTROPY 3.92071 PERPLEXITY 15.1444
Hmm: (3) VITERBI TRAIN CROSS-ENTROPY 4.40961 PERPLEXITY 21.2532

Hmm Iteration: 3 took: 0 seconds

-----------
Hmm: Iteration 4
A/D table contains 2469 parameters.
Hmm: (4) TRAIN CROSS-ENTROPY 3.65881 PERPLEXITY 12.6302
Hmm: (4) VITERBI TRAIN CROSS-ENTROPY 4.02462 PERPLEXITY 16.2754

Hmm Iteration: 4 took: 0 seconds

-----------
Hmm: Iteration 5
A/D table contains 2469 parameters.
Hmm: (5) TRAIN CROSS-ENTROPY 3.46288 PERPLEXITY 11.0263
Hmm: (5) VITERBI TRAIN CROSS-ENTROPY 3.74794 PERPLEXITY 13.4352

Hmm Iteration: 5 took: 0 seconds

Entire Hmm Training took: 0 seconds
==========================================================
Read classes: #words: 1624  #classes: 51
Read classes: #words: 2065  #classes: 51
Read classes: #words: 1624  #classes: 51
Read classes: #words: 2065  #classes: 51

==========================================================
Starting H333444:  Viterbi Training
 H333444 Training Started at: Tue May 26 02:29:08 2020


---------------------
THTo3: Iteration 1
#centers(pre/hillclimbed/real): 1 1 1  #al: 74.5322 #alsophisticatedcountcollection: 0 #hcsteps: 0
#peggingImprovements: 0
A/D table contains 2469 parameters.
A/D table contains 1423 parameters.
NTable contains 16250 parameter.
p0_count is 3756.41 and p1 is 281.796; p0 is 0.999 p1: 0.001
THTo3: TRAIN CROSS-ENTROPY 2.56756 PERPLEXITY 5.92806
THTo3: (1) TRAIN VITERBI CROSS-ENTROPY 2.73832 PERPLEXITY 6.67295

THTo3 Viterbi Iteration : 1 took: 0 seconds

---------------------
Model3: Iteration 2
#centers(pre/hillclimbed/real): 1 1 1  #al: 74.941 #alsophisticatedcountcollection: 0 #hcsteps: 1.74933
#peggingImprovements: 0
A/D table contains 2469 parameters.
A/D table contains 1423 parameters.
NTable contains 16250 parameter.
p0_count is 4294.52 and p1 is 12.7376; p0 is 0.999 p1: 0.001
Model3: TRAIN CROSS-ENTROPY 3.53882 PERPLEXITY 11.6223
Model3: (2) TRAIN VITERBI CROSS-ENTROPY 3.63118 PERPLEXITY 12.3907

Model3 Viterbi Iteration : 2 took: 0 seconds

---------------------
Model3: Iteration 3
#centers(pre/hillclimbed/real): 1 1 1  #al: 75.193 #alsophisticatedcountcollection: 0 #hcsteps: 1.81635
#peggingImprovements: 0
A/D table contains 2469 parameters.
A/D table contains 1420 parameters.
NTable contains 16250 parameter.
p0_count is 4313.21 and p1 is 3.39414; p0 is 0.999 p1: 0.001
Model3: TRAIN CROSS-ENTROPY 3.21687 PERPLEXITY 9.2977
Model3: (3) TRAIN VITERBI CROSS-ENTROPY 3.27777 PERPLEXITY 9.69855

Model3 Viterbi Iteration : 3 took: 0 seconds

---------------------
T3To4: Iteration 4
#centers(pre/hillclimbed/real): 1 1 1  #al: 75.3217 #alsophisticatedcountcollection: 6.66756 #hcsteps: 1.71716
#peggingImprovements: 0
D4 table contains 385903 parameters.
A/D table contains 2469 parameters.
A/D table contains 1408 parameters.
NTable contains 16250 parameter.
p0_count is 4315.26 and p1 is 2.36885; p0 is 0.999 p1: 0.001
T3To4: TRAIN CROSS-ENTROPY 3.09515 PERPLEXITY 8.54541
T3To4: (4) TRAIN VITERBI CROSS-ENTROPY 3.14184 PERPLEXITY 8.8265

T3To4 Viterbi Iteration : 4 took: 0 seconds

---------------------
Model4: Iteration 5
#centers(pre/hillclimbed/real): 1 1 1  #al: 75.3981 #alsophisticatedcountcollection: 5.02547 #hcsteps: 1.64477
#peggingImprovements: 0
D4 table contains 385903 parameters.
A/D table contains 2469 parameters.
A/D table contains 1392 parameters.
NTable contains 16250 parameter.
p0_count is 4315.96 and p1 is 2.02134; p0 is 0.999 p1: 0.001
Model4: TRAIN CROSS-ENTROPY 2.66446 PERPLEXITY 6.33991
Model4: (5) TRAIN VITERBI CROSS-ENTROPY 2.69512 PERPLEXITY 6.47606

Model4 Viterbi Iteration : 5 took: 0 seconds

---------------------
Model4: Iteration 6
#centers(pre/hillclimbed/real): 1 1 1  #al: 75.4437 #alsophisticatedcountcollection: 4.32306 #hcsteps: 1.57507
#peggingImprovements: 0
D4 table contains 385903 parameters.
A/D table contains 2469 parameters.
A/D table contains 1392 parameters.
NTable contains 16250 parameter.
p0_count is 4316.6 and p1 is 1.69944; p0 is 0.999 p1: 0.001
Model4: TRAIN CROSS-ENTROPY 2.58108 PERPLEXITY 5.98387
Model4: (6) TRAIN VITERBI CROSS-ENTROPY 2.60253 PERPLEXITY 6.07352

Model4 Viterbi Iteration : 6 took: 0 seconds
H333444 Training Finished at: Tue May 26 02:29:08 2020


Entire Viterbi H333444 Training took: 0 seconds
==========================================================

Entire Training took: 0 seconds
Program Finished at: Tue May 26 02:29:08 2020

==========================================================
Executing: rm -f /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/giza.pan-ashaninka-spanish/pan-ashaninka-spanish.A3.final.gz
Executing: gzip /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/giza.pan-ashaninka-spanish/pan-ashaninka-spanish.A3.final
(3) generate word alignment @ Tue May 26 02:29:08 UTC 2020
Combining forward and inverted alignment from files:
  /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/giza.spanish-pan-ashaninka/spanish-pan-ashaninka.A3.final.{bz2,gz}
  /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/giza.pan-ashaninka-spanish/pan-ashaninka-spanish.A3.final.{bz2,gz}
Executing: mkdir -p /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model
Executing: /home/hinantin/ashaninka/mosesdecoder/scripts/training/giza2bal.pl -d "gzip -cd /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/giza.pan-ashaninka-spanish/pan-ashaninka-spanish.A3.final.gz" -i "gzip -cd /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/giza.spanish-pan-ashaninka/spanish-pan-ashaninka.A3.final.gz" |/home/hinantin/ashaninka/mosesdecoder/scripts/../bin/symal -alignment="grow" -diagonal="yes" -final="yes" -both="yes" > /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/aligned.grow-diag-final-and
symal: computing grow alignment: diagonal (1) final (1)both-uncovered (1)
skip=<0> counts=<746>
(4) generate lexical translation table 0-0 @ Tue May 26 02:29:09 UTC 2020
(/home/hinantin/ashaninka/AshaninkaMT/moses/sentences.clean.spanish,/home/hinantin/ashaninka/AshaninkaMT/moses/sentences.clean.pan-ashaninka,/home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/lex)
!
Saved: /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/lex.f2e and /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/lex.e2f
FILE: /home/hinantin/ashaninka/AshaninkaMT/moses/sentences.clean.pan-ashaninka
FILE: /home/hinantin/ashaninka/AshaninkaMT/moses/sentences.clean.spanish
FILE: /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/aligned.grow-diag-final-and
(5) extract phrases @ Tue May 26 02:29:09 UTC 2020
/home/hinantin/ashaninka/mosesdecoder/scripts/generic/extract-parallel.perl 8 split "sort    " /home/hinantin/ashaninka/mosesdecoder/scripts/../bin/extract /home/hinantin/ashaninka/AshaninkaMT/moses/sentences.clean.pan-ashaninka /home/hinantin/ashaninka/AshaninkaMT/moses/sentences.clean.spanish /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/aligned.grow-diag-final-and /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/extract 7 orientation --model wbe-msd --GZOutput 
Executing: /home/hinantin/ashaninka/mosesdecoder/scripts/generic/extract-parallel.perl 8 split "sort    " /home/hinantin/ashaninka/mosesdecoder/scripts/../bin/extract /home/hinantin/ashaninka/AshaninkaMT/moses/sentences.clean.pan-ashaninka /home/hinantin/ashaninka/AshaninkaMT/moses/sentences.clean.spanish /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/aligned.grow-diag-final-and /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/extract 7 orientation --model wbe-msd --GZOutput 
MAX 7 1 0
Started Tue May 26 02:29:09 2020
using gzip 
isBSDSplit=0 
Executing: mkdir -p /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16171; ls -l /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16171 
total=746 line-per-split=94 
split -d -l 94 -a 7 /home/hinantin/ashaninka/AshaninkaMT/moses/sentences.clean.spanish /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16171/source.split -d -l 94 -a 7 /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/aligned.grow-diag-final-and /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16171/align.split -d -l 94 -a 7 /home/hinantin/ashaninka/AshaninkaMT/moses/sentences.clean.pan-ashaninka /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16171/target.merging extract / extract.inv
gunzip -c /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16171/extract.0000000.gz /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16171/extract.0000001.gz /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16171/extract.0000002.gz /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16171/extract.0000003.gz /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16171/extract.0000004.gz /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16171/extract.0000005.gz /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16171/extract.0000006.gz /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16171/extract.0000007.gz  | LC_ALL=C sort     -T /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16171 2>> /dev/stderr | gzip -c > /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/extract.sorted.gz 2>> /dev/stderr 
gunzip -c /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16171/extract.0000000.inv.gz /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16171/extract.0000001.inv.gz /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16171/extract.0000002.inv.gz /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16171/extract.0000003.inv.gz /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16171/extract.0000004.inv.gz /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16171/extract.0000005.inv.gz /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16171/extract.0000006.inv.gz /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16171/extract.0000007.inv.gz  | LC_ALL=C sort     -T /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16171 2>> /dev/stderr | gzip -c > /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/extract.inv.sorted.gz 2>> /dev/stderr 
gunzip -c /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16171/extract.0000000.o.gz /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16171/extract.0000001.o.gz /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16171/extract.0000002.o.gz /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16171/extract.0000003.o.gz /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16171/extract.0000004.o.gz /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16171/extract.0000005.o.gz /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16171/extract.0000006.o.gz /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16171/extract.0000007.o.gz  | LC_ALL=C sort     -T /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16171 2>> /dev/stderr | gzip -c > /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/extract.o.sorted.gz 2>> /dev/stderr 
Finished Tue May 26 02:29:09 2020
(6) score phrases @ Tue May 26 02:29:09 UTC 2020
(6.1)  creating table half /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/phrase-table.half.f2e @ Tue May 26 02:29:09 UTC 2020
/home/hinantin/ashaninka/mosesdecoder/scripts/generic/score-parallel.perl 8 "sort    " /home/hinantin/ashaninka/mosesdecoder/scripts/../bin/score /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/extract.sorted.gz /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/lex.f2e /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/phrase-table.half.f2e.gz  0 
Executing: /home/hinantin/ashaninka/mosesdecoder/scripts/generic/score-parallel.perl 8 "sort    " /home/hinantin/ashaninka/mosesdecoder/scripts/../bin/score /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/extract.sorted.gz /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/lex.f2e /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/phrase-table.half.f2e.gz  0 
using gzip 
Started Tue May 26 02:29:09 2020
/home/hinantin/ashaninka/mosesdecoder/scripts/../bin/score /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16232/extract.0.gz /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/lex.f2e /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16232/phrase-table.half.0000000.gz  2>> /dev/stderr 
/home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16232/run.0.sh/home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16232/run.1.sh/home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16232/run.2.sh/home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16232/run.3.sh/home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16232/run.4.sh/home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16232/run.5.sh/home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16232/run.6.sh/home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16232/run.7.shmv /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16232/phrase-table.half.0000000.gz /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/phrase-table.half.f2e.gzrm -rf /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16232 
Finished Tue May 26 02:29:09 2020
(6.3)  creating table half /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/phrase-table.half.e2f @ Tue May 26 02:29:09 UTC 2020
/home/hinantin/ashaninka/mosesdecoder/scripts/generic/score-parallel.perl 8 "sort    " /home/hinantin/ashaninka/mosesdecoder/scripts/../bin/score /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/extract.inv.sorted.gz /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/lex.e2f /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/phrase-table.half.e2f.gz --Inverse 1 
Executing: /home/hinantin/ashaninka/mosesdecoder/scripts/generic/score-parallel.perl 8 "sort    " /home/hinantin/ashaninka/mosesdecoder/scripts/../bin/score /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/extract.inv.sorted.gz /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/lex.e2f /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/phrase-table.half.e2f.gz --Inverse 1 
using gzip 
Started Tue May 26 02:29:09 2020
/home/hinantin/ashaninka/mosesdecoder/scripts/../bin/score /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16278/extract.0.gz /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/lex.e2f /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16278/phrase-table.half.0000000.gz --Inverse  2>> /dev/stderr 
/home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16278/run.1.sh/home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16278/run.2.sh/home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16278/run.0.sh/home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16278/run.3.sh/home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16278/run.4.sh/home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16278/run.5.sh/home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16278/run.6.sh/home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16278/run.7.shgunzip -c /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16278/phrase-table.half.*.gz 2>> /dev/stderr| LC_ALL=C sort     -T /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16278  | gzip -c > /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/phrase-table.half.e2f.gz  2>> /dev/stderr rm -rf /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/tmp.16278 
Finished Tue May 26 02:29:09 2020
(6.6) consolidating the two halves @ Tue May 26 02:29:09 UTC 2020
Executing: /home/hinantin/ashaninka/mosesdecoder/scripts/../bin/consolidate /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/phrase-table.half.f2e.gz /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/phrase-table.half.e2f.gz /dev/stdout | gzip -c > /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/phrase-table.gz
Consolidate v2.0 written by Philipp Koehn
consolidating direct and indirect rule tables

Executing: rm -f /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/phrase-table.half.*
(7) learn reordering model @ Tue May 26 02:29:09 UTC 2020
(7.1) [no factors] learn reordering model @ Tue May 26 02:29:09 UTC 2020
(7.2) building tables @ Tue May 26 02:29:09 UTC 2020
Executing: /home/hinantin/ashaninka/mosesdecoder/scripts/../bin/lexical-reordering-score /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/extract.o.sorted.gz 0.5 /home/hinantin/ashaninka/AshaninkaMT/moses/working/train/model/reordering-table. --model "wbe msd wbe-msd-bidirectional-fe"
Lexical Reordering Scorer
scores lexical reordering models of several types (hierarchical, phrase-based and word-based-extraction
(8) learn generation model @ Tue May 26 02:29:09 UTC 2020
  no generation model requested, skipping step
(9) create moses.ini @ Tue May 26 02:29:09 UTC 2020
